{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fdca7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ebef9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6169,  0.5451, -0.1838], requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aurograd_package_provides_autmatic_differentiation\n",
    "x=torch.randn(3, requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fae232e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.3831, 2.5451, 1.8162], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=x+2\n",
    "y#gradient_Function_attribute_as_it_is_created_by_applying_function_on_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78f51193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x14d422020>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)#grad_fun:references_a_function_that_created_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fef545ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.7386, 19.4327,  9.8959], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=y*y*3\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b71b020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.6891, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=z.mean()\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e5c9bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "941719ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.7661, 5.0902, 3.6324])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)#dz/dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "291c3e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1555,  1.2289],\n",
       "        [-0.3314, -0.4207]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stop_a_tensor_from_tracking_history\n",
    "a=torch.randn(2,2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd5daa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(a.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52fc0183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "b=((a*3)/(a-1))\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c010ba42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1555,  1.2289],\n",
       "        [-0.3314, -0.4207]], requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bc0d381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(a.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f18ac45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=(a*a).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a62dc03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SumBackward0 object at 0x14d414e20>\n"
     ]
    }
   ],
   "source": [
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d04236c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#detach():-get_a_new_tensor_with_same_content_but_no_gradient_computation\n",
    "a=torch.randn(2, 2, requires_grad=True)\n",
    "print(a.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df11fe7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "b=a.detach()\n",
    "print(b.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84fd0e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "a=torch.randn(2, 2 , requires_grad=True)\n",
    "print(a.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1af131c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print((x**2).requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d50a281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([0.1000, 0.1000, 0.1000, 0.1000], requires_grad=True)\n",
      "tensor(4.8000, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Emptying_Gradients-need_to.zero()_the_gradients_before_updating_the_weights_and_before_going_to_next_iteration\n",
    "weights=torch.ones(4, requires_grad=True)\n",
    "for epoch in range(3):\n",
    "    model_output=(weights*3).sum()\n",
    "    model_output.backward()\n",
    "    print(weights.grad)\n",
    "    with torch.no_grad():\n",
    "        weights-= 0.1*weights.grad\n",
    "    weights.grad.zero_()\n",
    "print(weights)\n",
    "print(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e68467d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<PowBackward0>)\n",
      "tensor(-2.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Backpropagation_for_linear_Regression\n",
    "x= torch.tensor(1.0)\n",
    "y= torch.tensor(2.0)\n",
    "\n",
    "w= torch.tensor(1.0, requires_grad=True)\n",
    "\n",
    "#forward_pass_to_computer_loss\n",
    "y_predicted= w*x\n",
    "loss= (y_predicted-y)**2\n",
    "print(loss)\n",
    "\n",
    "#backward_pass_to_compute_gradient\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    w-= 0.01*w.grad\n",
    "w.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65cb4454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Before Training:f(5)=0.000\n",
      "epoch 1:w=0.300, loss=30.00000000\n",
      "epoch 11:w=1.665, loss=1.16278565\n",
      "epoch 21:w=1.934, loss=0.04506905\n",
      "epoch 31:w=1.987, loss=0.00174685\n",
      "epoch 41:w=1.997, loss=0.00006770\n",
      "epoch 51:w=1.999, loss=0.00000262\n",
      "epoch 61:w=2.000, loss=0.00000010\n",
      "epoch 71:w=2.000, loss=0.00000000\n",
      "epoch 81:w=2.000, loss=0.00000000\n",
      "epoch 91:w=2.000, loss=0.00000000\n",
      "Prediction after Training:f(5)=10.000\n"
     ]
    }
   ],
   "source": [
    "#Gradient_Descent_for_linear_Regression\n",
    "import numpy as np\n",
    "X=np.array([1, 2, 3, 4], dtype=np.float32)\n",
    "Y=np.array([2, 4, 6, 8], dtype=np.float32)\n",
    "w=0.0\n",
    "def forward(x):\n",
    "    return w*x\n",
    "def loss(y, y_pred):\n",
    "    return ((y_pred-y)**2).mean()\n",
    "def gradient(x, y, y_pred):\n",
    "    return np.mean(2*x*(y_pred-y))\n",
    "print(f'Prediction Before Training:f(5)={forward(5):.3f}')\n",
    "\n",
    "#Training\n",
    "learning_rate=0.01\n",
    "n_iters=100\n",
    "for epoch in range(n_iters):\n",
    "    y_pred=forward(X)\n",
    "    l=loss(Y, y_pred)\n",
    "    dw=gradient(X, Y, y_pred)\n",
    "    w=w-learning_rate*dw\n",
    "    if epoch%10==0:\n",
    "        print(f'epoch {epoch+1}:w={w:.3f}, loss={l:.8f}')\n",
    "print(f'Prediction after Training:f(5)={forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c6b74ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training:f(5)=0.000\n",
      "epoch 1: w=0.300, loss=30.00000000\n",
      "epoch 11: w=1.665, loss=1.16278565\n",
      "epoch 21: w=1.934, loss=0.04506890\n",
      "epoch 31: w=1.987, loss=0.00174685\n",
      "epoch 41: w=1.997, loss=0.00006770\n",
      "epoch 51: w=1.999, loss=0.00000262\n",
      "epoch 61: w=2.000, loss=0.00000010\n",
      "epoch 71: w=2.000, loss=0.00000000\n",
      "epoch 81: w=2.000, loss=0.00000000\n",
      "epoch 91: w=2.000, loss=0.00000000\n",
      "Prediction after training: f(5)=10.000\n"
     ]
    }
   ],
   "source": [
    "#Gradient_Descent_Automatic\n",
    "X=torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "Y=torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "w=torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "def forward(x):\n",
    "    return w*x\n",
    "def loss(y, y_pred):\n",
    "    return ((y_pred-y)**2).mean()\n",
    "print(f'Prediction before training:f(5)={forward(5).item():.3f}')\n",
    "\n",
    "learning_rate=0.01\n",
    "n_iters=100\n",
    "for epoch in range(n_iters):\n",
    "    y_pred=forward(X)\n",
    "    l=loss(Y, y_pred)\n",
    "    l.backward()\n",
    "    dw=w.grad\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        w-=learning_rate*dw\n",
    "        \n",
    "    w.grad.zero_()\n",
    "    if epoch%10==0:\n",
    "        print(f'epoch {epoch+1}: w={w.item():.3f}, loss={l.item():.8f}')\n",
    "print(f'Prediction after training: f(5)={forward(5).item():.3f}')\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
